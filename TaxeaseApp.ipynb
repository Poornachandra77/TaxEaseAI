{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE1pjJIhBzsR",
        "outputId": "475d9efc-96a6-4bb9-9c82-6fcb292a4bfd"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import openai\n",
        "import pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI as LangOpenAI\n",
        "from langchain.vectorstores import Pinecone as LangPinecone\n",
        "import jsonlines\n",
        "from PyPDF2 import PdfReader\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yM0ReTomCuJ9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone with your API key\n",
        "pc = Pinecone(api_key=\"d8f32a14-b0b1-40bf-bbc1-b93f9f8b6c8d\")\n",
        "\n",
        "# Example: Create a new index if it doesn't exist\n",
        "if 'taxease' not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name='taxease',\n",
        "        dimension=1536,  # Specify the dimension of your embeddings\n",
        "        metric='euclidean',  # You can change this depending on your needs\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-west-2'\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Connect to the \"taxease\" index\n",
        "index = pc.Index(\"taxease\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VGy09J3Bi24",
        "outputId": "55cf7f22-bdd6-4205-d279-e999760b63c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-13 00:32:07.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.779 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.788 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2024-12-13 00:32:07.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-13 00:32:07.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "# Adding custom CSS for buttons and layout\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .stButton>button {\n",
        "        background-color: #6200ea;\n",
        "        color: white;\n",
        "        border-radius: 10px;\n",
        "        font-size: 16px;\n",
        "        padding: 10px 20px;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: #3700b3;\n",
        "    }\n",
        "\n",
        "    .stTextInput input {\n",
        "        border-radius: 5px;\n",
        "        border: 1px solid #ddd;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Title\n",
        "st.title(\"TaxEase AI\")\n",
        "\n",
        "# Subtitle and description for better user guidance\n",
        "st.subheader(\"Upload your tax documents (PDF or JSONL) for analysis.\")\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    **TaxEase AI** helps you analyze and query your tax documents using advanced AI techniques.\n",
        "    Upload a tax document below to get started.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Add a placeholder for the image to make the UI more interactive\n",
        "image = Image.open('image.webp')  # Replace with the correct image path\n",
        "st.image(image, caption='TaxEase AI', use_column_width=True)\n",
        "\n",
        "# Custom file uploader with enhanced design\n",
        "uploaded_file = st.file_uploader(\"Drag and drop a JSONL or PDF file here\", type=[\"jsonl\", \"pdf\"])\n",
        "\n",
        "# Display a message if no file is uploaded\n",
        "if uploaded_file is None:\n",
        "    st.warning(\"Please upload a file to proceed.\")\n",
        "else:\n",
        "    # Your file processing code here\n",
        "    st.success(f\"Successfully uploaded: {uploaded_file.name}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess and load JSONL data\n",
        "def load_jsonl_data(file):\n",
        "    with jsonlines.open(file) as reader:\n",
        "        return [entry for entry in reader]\n",
        "\n",
        "def preprocess_jsonl(file):\n",
        "    data = []\n",
        "    with open(file, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                try:\n",
        "                    json_line = json.loads(line)\n",
        "                    data.append({\n",
        "                        \"id\": f\"jsonl-{len(data)}\",\n",
        "                        \"text\": f\"{json_line['prompt']} {json_line['completion']}\",\n",
        "                        \"metadata\": json_line\n",
        "                    })\n",
        "                except json.JSONDecodeError as e:\n",
        "                    st.warning(f\"Skipping invalid JSON line: {line}\")\n",
        "    return data\n",
        "\n",
        "# Preprocess PDF data\n",
        "def preprocess_pdf(file):\n",
        "    reader = PdfReader(file)\n",
        "    pdf_text = \"\"\n",
        "    for page in reader.pages:\n",
        "        pdf_text += page.extract_text()\n",
        "\n",
        "    chunks = pdf_text.split(\"\\n\\n\")\n",
        "    return [\n",
        "        {\n",
        "            \"id\": f\"pdf-{i}\",\n",
        "            \"text\": chunk.strip(),\n",
        "            \"metadata\": {\"source\": \"PDF\", \"page\": i}\n",
        "        }\n",
        "        for i, chunk in enumerate(chunks) if chunk.strip()\n",
        "    ]\n",
        "\n",
        "# Handle file types\n",
        "if uploaded_file is not None:\n",
        "    if uploaded_file.type == \"application/jsonl\":\n",
        "        data = preprocess_jsonl(uploaded_file)\n",
        "        st.write(f\"Loaded {len(data)} records from the JSONL file.\")\n",
        "    elif uploaded_file.type == \"application/pdf\":\n",
        "        data = preprocess_pdf(uploaded_file)\n",
        "        st.write(f\"Extracted {len(data)} chunks from the PDF.\")\n",
        "\n",
        "    # Set up Pinecone index and store data\n",
        "    index_name = \"taxease\"  # Example index name\n",
        "    try:\n",
        "        index = pinecone.Index(index_name)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to connect to Pinecone: {e}\")\n",
        "\n",
        "    # Add data to Pinecone index (for simplicity, assuming it's a text embedding model)\n",
        "    for record in data:\n",
        "        index.upsert([(record['id'], record['text'])])\n",
        "\n",
        "    # Create the retrieval-based QA chain\n",
        "    retriever = LangPinecone(index=index, namespace=\"default\", embedding_function=\"openai\")\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        LangOpenAI(), retriever=retriever\n",
        "    )\n",
        "\n",
        "    # Input field for conversation\n",
        "    user_input = st.text_input(\"Ask a question:\")\n",
        "\n",
        "    if user_input:\n",
        "        response = qa_chain.run(user_input)\n",
        "        st.write(response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
